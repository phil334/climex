% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/opti.R
\name{fit.gpd.default}
\alias{fit.gpd.default}
\title{Improved maximum-likelihood fit of the generalized Pareto
  (GP) distribution}
\usage{
\method{fit.gpd}{default}(x, initial = NULL, threshold = NULL,
  likelihood.function = likelihood,
  gradient.function = likelihood.gradient, error.estimation = c("MLE",
  "MC", "bootstrap", "none"), monte.carlo.sample.size = 100,
  bootstrap.sample.size = 100, return.period = 100,
  total.length = NULL, extreme.type = c("max", "min"),
  thresholding = FALSE, decluster = NULL, cluster.distance = NULL,
  silent = FALSE, debug = FALSE, mc.cores = NULL, ...)
}
\arguments{
\item{x}{A numerical vector, which should be distributed according
to the GP distribution. The data is assumed to correspond to
annual time stamp. If another underlying time unit was chosen,
the return levels are \emph{NOT} corresponding to the return
periods in their names! This is a fallback method. Please use
\pkg{xts} class data instead to assure full compatibility with
the \pkg{climex} package.}

\item{initial}{Initial values for the GP parameters. Has to be
provided as 2x1 vector. If NULL the parameters are estimated
with the function \code{\link{likelihood.initials}}. If the
shape parameter is set to 0 the exponential distribution instead
of the GP one is fitted. But this its strongly discouraged to do
so! Default = NULL}

\item{threshold}{Optional threshold used to extract the
exceedances from the provided series \strong{x}. If present it
will be added to the return level to produce a value which fits
to underlying time series. If the user wants the exceedances to
be calculated within this function, this argument is a mandatory
one. Default = NULL.}

\item{likelihood.function}{Function which is going to be
optimized. Default: \code{\link{likelihood}}}

\item{gradient.function}{If NULL a finite difference method is
invoked. To use the derived formula from the GP likelihood
gradient provide \code{\link{likelihood.gradient}}.
Default = \code{\link{likelihood.gradient}}.}

\item{error.estimation}{Method for calculating the standard errors
  of the fitted results. The errors of the GP parameters will be
  calculated as the square roots of the diagonal elements of the
  inverse of the hessian matrix. The latter will be evaluated at
  the maximum likelihood estimates (MLE) of the GP parameters.

  \emph{MLE}: The standard error of the return level is
    calculated using the Delta method and the maximum likelihood
    estimates of the GP parameters. Note: For positive shape
    parameters bigger than 0.3 this approach tends to highly
    overestimates the errors of the return levels.

  \emph{MC}: Alternative one can use a Monte Carlo method for
    which \strong{monte.carlo.sample.size} samples of the same
    size as \emph{x} will be drawn from a GP distribution
    constituted by the obtained MLE of the GP parameters of
    \strong{x}. The standard error is then calculated via the
    square of the variance of all fitted GP parameters and
    calculated return levels. Note: In its essence this approach
    is not an estimation of the error involved in fitting the time
    series to a GP distribution. It is rather the mean error of
    fitting a GP distribution with the same length and parameters
    as estimated ones.

  \emph{bootstrap}: Using this option the provided time series
    \strong{x} will be sampled with replacement
    \strong{bootstrap.sample.size} times and with the same length
    as the original time series. The standard errors of the GP
    parameters and return levels of all those sampled series is
    calculated and returned as an estimate of the fitting error.
    Note: Since the data is (hopefully) GP-distributed, such a
    sampling has to be treated with a lot of care.

    Sometimes the inversion of the hessian fails (since the are
    some NaN in the hessian) when calculating the error estimates
    using the maximum likelihood approach (MLE) (which is also the
    reason why the \pkg{ismev} package occasionally does not
    work). In such cases the Monte Carlo (MC) method is used as a
    fallback. 

  \emph{none} skips the calculation of the error. Default = "MLE".}

\item{monte.carlo.sample.size}{Number of samples used to obtain
the Monte Carlo estimate of the standard error of the fitting.
Default = 100.}

\item{bootstrap.sample.size}{Number of samples with replacements
to drawn from the original series \emph{x} in order to determine
the standard errors for the GP parameters and return
levels. Default = 100.}

\item{return.period}{Quantiles at which the return level is going
to be evaluated. Class \emph{numeric}. Default = 100.}

\item{total.length}{Uses the maximum likelihood estimator to
calculate the probability of a measurement to be an
exceedance. Else an estimate based on the mean number of
exceedances in the available years (time stamps of the class
\pkg{xts} time series) will be used. Default = NULL.}

\item{extreme.type}{String specifying whether the exceedances over
a very high ("max") or low ("min") threshold should be
fitted. If the low one is chosen, the input \strong{x} has to be
either a time series of all points below the \strong{threshold}
with the \strong{threshold} subtracted or the raw series and
fit.gpd function will handle the extraction of the minima
internally. For the minima the resulting extremes are multiplied
by -1 and fitted using a default GP distribution. The resulting
scale and shape parameter are handed back without any additional
changes and the return levels are multiplied by -1. Default =
"max".}

\item{thresholding}{Automated thresholding is disabled in the
fallback method.}

\item{decluster}{Logical flag indicating whether or not to
decluster the obtained exceedances over the
\strong{threshold}. Default = TRUE.}

\item{cluster.distance}{Numerical value specifying how many points
have to be below the \strong{threshold} for the next point to be
considered the starting point of a new cluster. Only supply a
value when you really know what you are doing! Default = NULL.}

\item{silent}{Determines whether or not warning messages shall be
displayed and results shall be reported. Default = FALSE.}

\item{debug}{If TRUE the routine will display debugging
information featuring intermediate steps of the constrained
optimization. Default = FALSE.}

\item{mc.cores}{A numerical input specifying the number of cores
to use for the multi core application of the function (see
\code{\link[parallel]{detectCores}}). This functionality is only
available if the input is a list of different objects. If NULL,
the function will be calculated classically with only one core.
Default = NULL.}

\item{...}{Additional arguments for the \code{\link[stats]{optim}}
function.}
}
\value{
Output of the optim function with class \code{c( "list",
  "climex.fit.gpd" )}
  \itemize{
    \item{ par = MLE of the GP parameters }
    \item{ value = Value of the negative log-likelihood
             evaluated at the MLE }
    \item{ counts = Number of evaluations of the likelihood
             function and its gradient during optimization (inner
             routine) } 
    \item{ outer.iteration = Number of updates of the penalty and
             the Lagrangian parameter to fine-tune the impact of
             the constraints on the optimization (outer routine) }
     \item{ return.level = Estimate of the return levels at the
             provided return periods }
     \item{ se = Standard error of the GP parameters and the
             return levels }
     \item{ x = Threshold exceedances }
     \item{ threshold = Value which had to be exceeded }
     \item{ control = Parameter and options used during
             optimization } 
   }
  If, on the other hand, a list of \pkg{xts} class object was
  provided, a list of objects structured as describe above is
  returned.
}
\description{
This function fits the Generalized Pareto
  distribution (GP) to the supplied data, which have to be
  threshold exceedances with the corresponding threshold already
  subtracted. The determination of the starting point for the
  optimization and the calculation of the return level and the all
  the corresponding estimates of the fitting errors will be done
  internally.
}
\details{
The optimization is performed by the augmented Lagrangian
  method using the \code{\link{auglag}} function of the
  \pkg{alabama} package. Within this framework the log-likelihood
  function of the GP gets augmented with N+2 constraints, where N
  is the number of points in the time series. N+1 of those
  constraints ensure the log-likelihood (containing two
  logarithms) to be always defined. The remaining constraints
  ensures for the shape parameter to be always bigger than -1 for
  the maximum likelihood to be defined in the first place. The
  penalty in the log-likelihood function is the sum of all squared
  constrain violations plus an additional term linear in the
  constraint violation to ensure well-conditioning. Using this
  penalty term the problem becomes unconstrained again and can be
  solved using \code{\link[stats]{optim}}. After each of those
  inner routines the weighting parameter of the penalty is being
  increased until some convergence conditions are fulfilled.

  Since it usually takes just four to five outer iterations this
  functions needs only double the time a pure call to the
  \code{\link[stats]{optim}} function would need.

  The \strong{total.length} argument refers to the length of the
  original time series before the thresholding was applied. If
  present it will be used to calculate the maximum likelihood
  estimate of the probability of an observation to be a threshold
  exceedance (necessary to determine the estimation errors for the
  calculated return levels). Else an estimator based on mean
  number of exceedances per year will be used.

  If the user instead wants to fit just the exponential
  distribution and not the entire GP distribution, the shape
  parameter of the \strong{initial} has to be set to 0. But in
  practice this is strongly discouraged since it will yield
  inferior results.

  I found the Nelder-Mead method to be more robust to starting
  points more far away from the global optimum. This also holds
  for the inner routine of the augmented Lagrangian method. Since
  other routines, like CG and BFGS only cause problems in the
  extreme value analysis, there won't be an option to choose them
  in this package.
}
\examples{
  potsdam.anomalies <- anomalies( temp.potsdam )
  potsdam.extremes <- threshold( potsdam.anomalies,
                                threshold = 10,
                                decluster = TRUE )
  fit.gpd( potsdam.extremes )
}
\seealso{
Other optimization: \code{\link{fit.gev.default}},
  \code{\link{fit.gev.list}}, \code{\link{fit.gev.xts}},
  \code{\link{fit.gev}}, \code{\link{fit.gpd.list}},
  \code{\link{fit.gpd.xts}}, \code{\link{fit.gpd}},
  \code{\link{likelihood.augmented}},
  \code{\link{likelihood.gradient.augmented}},
  \code{\link{likelihood.gradient}},
  \code{\link{likelihood.initials}},
  \code{\link{likelihood}}
}
\author{
Philipp Mueller
}
\concept{optimization}
